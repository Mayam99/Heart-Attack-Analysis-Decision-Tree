# -*- coding: utf-8 -*-
"""Heart-Attack-Analysis-DecisionTree.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1slpKE3u2dWdjOl8kyeJg0twPSWsFSYTu

#Introduction
###Heart attack analysis, also known as heart disease prediction or cardiovascular disease prediction, is a critical application of data science and machine learning aimed at predicting the likelihood of an individual experiencing a heart attack based on various factors and indicators. This analysis typically involves the use of datasets containing information about patients' medical history, lifestyle habits, physiological measurements, and other relevant features.

###The goal of heart attack analysis is to develop predictive models that can accurately classify individuals into different risk categories, such as low, medium, or high risk of experiencing a heart attack within a certain timeframe. Decision tree algorithms are commonly used in this context due to their ability to handle both numerical and categorical data, as well as their interpretability, which allows healthcare professionals to understand and explain the reasoning behind the predictions.

###By leveraging advanced analytics techniques, heart attack analysis can help healthcare providers identify high-risk individuals early on, allowing for proactive intervention strategies such as lifestyle modifications, medication management, and targeted monitoring. This ultimately contributes to reducing the incidence of heart attacks and improving patient outcomes.

#About the Dataset

###age: Age of the patient
###sex: Gender of the patient
###cp: Chest pain type, 0 = Typical Angina, 1 = Atypical Angina, 2 = Non-anginal Pain, 3 = Asymptomatic
###trtbps: Resting blood pressure (in mm Hg)
###chol: Cholestoral in mg/dl fetched via BMI sensor
###fbs: (fasting blood sugar > 120 mg/dl), 1 = True, 0 = False
###restecg: Resting electrocardiographic results, 0 = Normal, 1 = ST-T wave normality, 2 = Left ventricular hypertrophy
###thalachh: Maximum heart rate achieved
###oldpeak: Previous peak
###slp: Slope
###caa: Number of major vessels
###thall: Thalium Stress Test result ~ (0,3)
###exng: Exercise induced angina ~ 1 = Yes, 0 = No
###output: Target variable

#Importing Necessary Libraries
"""

import pandas as pd #Pandas is a powerful data manipulation and analysis library.
import numpy as np  #NumPy is a powerful tool for numerical computations in Python
import matplotlib.pyplot as plt # Matplotlib is a comprehensive library for creating static, animated, and interactive visualizations in Python.
import seaborn as sn # Seaborn is a statistical data visualization library based on Matplotlib
import warnings #The import warnings; warnings.filterwarnings("ignore") line is used to suppress warning messages in the code to keep the output clean.
warnings.filterwarnings("ignore")

"""##Loading the Dataset"""

df= pd.read_csv("heart (1).csv") #The df.head() command displays the first five rows of the DataFrame df.

df.columns #The df.columns command returns an index object containing the column labels of the DataFrame df.

"""##Analyzing the Dataset"""

df # Display the first few and last few rows of the dataset.

"""##Checking the shape of the Dataset"""

df.shape #The df.shape command returns a tuple representing the dimensions of the DataFrame df, with the number of rows and columns.

"""## Checking if there is any Null value in the Data"""

df.isnull().sum() #The df.isnull().sum() command returns the count of missing values in each column of the DataFrame df.

"""###There is no Null value in the Dataframe"""

#Checking for unique data
df.nunique() #The df.nunique() command returns the number of unique values for each column in the DataFrame df

df.info() #The df.info() command provides a summary of the DataFrame df, including the number of non-null entries, data types, and memory usage.

"""###All attributes are of type 'int' except 'oldpeak'"""

# Checking for duplicate rows
duplicate_rows = df[df.duplicated()]

if duplicate_rows.empty:
    print("No duplicate values found.")
else:
    print("Duplicate values found:")
    print(duplicate_rows)

"""###Dropping the Duplicates

"""

df.drop_duplicates(inplace=True) # This  command removes duplicate rows from the DataFrame df and updates it in place.

df.shape #The df.shape command returns a tuple indicating the number of rows and columns in the DataFrame df.

df.head()

df.describe() #The df.describe() command generates summary statistics for the numerical columns in the DataFrame df.

"""###Computing the correlation matrix"""

df.corr() #The df.corr() command computes the correlation matrix for the numerical columns in the DataFrame df.

"""###The code df.corr() computes the correlation matrix for the variables in the DataFrame df. In other words, it calculates the correlation coefficients between all pairs of numerical columns in the DataFrame.

###Each cell in the correlation matrix represents the correlation coefficient between two variables. The correlation coefficient ranges from -1 to 1, where:

###1 indicates a perfect positive correlation (as one variable increases, the other also increases).
###-1 indicates a perfect negative correlation (as one variable increases, the other decreases).
###0 indicates no correlation between the variables.
###Here's what the output of df.corr() represents:

###If the value is close to 1, it suggests a strong positive correlation.
###If the value is close to -1, it suggests a strong negative correlation.
###If the value is close to 0, it suggests no correlation.

##Data preprocessing
"""

df=df.iloc[:, :14] #This  command selects the first 14 columns of the DataFrame df.
df

"""##There's no need for categorical encoding"""

x= df.iloc[:, 1:-1].values #The x = df.iloc[:, 1:-1].values extracts feature columns (excluding the first and last columns) as a NumPy array
y= df.iloc[:,-1].values #y = df.iloc[:, -1].values extracts the target column as a NumPy array
x, y  # x and y represent features and labels for modeling

"""##Splitting the data for Train and Test"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state= 42) #This command splits the feature and target arrays into training and testing sets, with 30% of the data reserved for testing.

print('Shape of the training data', x_train.shape, y_train.shape)
print('Shape of the test data', x_test.shape, y_test.shape)

from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from sklearn.tree import DecisionTreeClassifier
# Initialize the decision tree classifier
dt_classifier = DecisionTreeClassifier(max_depth=None, min_samples_leaf=1, criterion='gini')

# Fit the classifier to the training data
dt_classifier.fit(x_train, y_train)

# Predict on the testing data
y_pred = dt_classifier.predict(x_test)

# Evaluate the model's accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report

# Accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Precision
precision = precision_score(y_test, y_pred, average='weighted')
print("Precision:", precision)

# Recall
recall = recall_score(y_test, y_pred, average='weighted')
print("Recall:", recall)

# F1-score
f1 = f1_score(y_test, y_pred, average='weighted')
print("F1-score:", f1)

# Classification report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

"""###These scores are commonly used to evaluate the performance of a classification model. Here's a brief interpretation of each metric:

###Accuracy: This metric represents the proportion of correctly classified instances out of the total instances. In this case, the accuracy is approximately 0.846, indicating that around 84.6% of the instances were classified correctly by the model.

###Precision: Precision measures the proportion of true positive predictions out of all positive predictions made by the model. A precision score of approximately 0.847 suggests that when the model predicts a positive outcome, it is correct around 84.7% of the time.

###Recall (Sensitivity): Recall measures the proportion of true positive predictions out of all actual positive instances in the dataset. A recall score of approximately 0.846 indicates that the model correctly identifies around 84.6% of all actual positive instances.

###F1-score: The F1-score is the harmonic mean of precision and recall. It provides a balance between precision and recall, giving equal weight to both metrics. A higher F1-score indicates better performance, and in this case, the F1-score is approximately 0.846.

###Classification Report: This section provides a detailed breakdown of precision, recall, and F1-score for each class (in this case, classes 0 and 1). It also includes support, which represents the number of instances of each class in the dataset.
"""

from sklearn.tree import plot_tree
import matplotlib.pyplot as plt

# Generate predictions using the decision tree classifier
predictions = dt_classifier.predict(x_test)

# Access the classes_ attribute to get the class names
class_names = dt_classifier.classes_.astype(str)

# Plot the decision tree
plt.figure(figsize=(20, 10))
plot_tree(dt_classifier, class_names=class_names, filled=True)
plt.show()

import seaborn as sns
from sklearn.metrics import confusion_matrix

# Compute the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=dt_classifier.classes_, yticklabels=dt_classifier.classes_)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from sklearn.model_selection import cross_val_score

# Perform cross-validation
scores = cross_val_score(dt_classifier, x, y, cv=5, scoring='accuracy')

# Print cross-validation scores
print("Cross-validation scores:", scores)

# Calculate and print mean cross-validation score
mean_score = scores.mean()
print("Mean cross-validation score:", mean_score)

"""###These cross-validation scores are typically obtained by performing k-fold cross-validation on a machine learning model. Here's the interpretation:

###1) Cross-validation scores: These are the accuracy scores obtained for each fold of cross-validation. In k-fold cross-validation, the dataset is split into k subsets (or folds), and the model is trained and evaluated k times, with each fold used as the testing set once and the remaining folds as the training set.

###The cross-validation scores provided are:
###0.75409836
###0.81967213
####0.78333333
###0.75
####0.76666667
###These scores represent the accuracy achieved by the model on each fold of the cross-validation process. They can vary depending on the particular subset of data used for training and testing in each fold.

###2) Mean cross-validation score: This is the average of the cross-validation scores obtained across all folds. In this case, the mean cross-validation score is approximately 0.775.

The mean cross-validation score provides an overall assessment of the model's performance across multiple iterations of cross-validation. It gives an indication of how well the model is expected to perform on unseen data, providing more robustness than a single train-test split.

Overall, a mean cross-validation score of 0.775 suggests that the model's performance is reasonably consistent across different subsets of the data, indicating that it is likely to generalize well to new, unseen data.
"""